from flask import Flask, render_template, request, redirect, url_for, send_file, flash
import os
import uuid
from werkzeug.utils import secure_filename
import PyPDF2
import pdfplumber
import pandas as pd
import pytesseract
from PIL import Image
import io
import tempfile
import shutil

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
app.config['UPLOAD_FOLDER'] = os.path.abspath('uploads')
app.config['PROCESSED_FOLDER'] = os.path.abspath('processed')
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size

# Ensure upload directories exist
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['PROCESSED_FOLDER'], exist_ok=True)

# Configure Tesseract path (adjust for your system)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

ALLOWED_EXTENSIONS = {'pdf'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def extract_text_from_pdf(pdf_path):
    """Extract text from PDF using PyPDF2"""
    text = ""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
    except Exception as e:
        print(f"Error extracting text with PyPDF2: {e}")
        # Fallback to pdfplumber
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() or ""
        except Exception as e2:
            print(f"Error extracting text with pdfplumber: {e2}")
            return ""

    return text

def extract_tables_from_pdf(pdf_path):
    """Extract tables from PDF using pdfplumber"""
    tables_data = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                tables = page.extract_tables()
                for table_idx, table in enumerate(tables):
                    if table:
                        # Convert to DataFrame for easier handling
                        df = pd.DataFrame(table)
                        tables_data.append({
                            'page': page_num + 1,
                            'table_index': table_idx + 1,
                            'data': df
                        })
    except Exception as e:
        print(f"Error extracting tables: {e}")

    return tables_data

def perform_ocr_on_image(image):
    """Perform OCR on PIL Image"""
    try:
        text = pytesseract.image_to_string(image)
        return text
    except Exception as e:
        print(f"OCR error: {e}")
        return ""

def extract_text_with_ocr(pdf_path):
    """Extract text from scanned PDF using OCR"""
    text = ""
    try:
        # Use pdfplumber to convert pages to images for OCR
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                # Convert page to image
                img = page.to_image(resolution=300).original
                page_text = perform_ocr_on_image(img)
                text += f"\n--- Page {page_num + 1} ---\n{page_text}"
    except Exception as e:
        print(f"OCR extraction error: {e}")

    return text

def parse_invoice_data(text, pdf_path=None):
    """Parse common invoice fields from extracted text and tables"""
    import re

    # First extract common fields that apply to the entire invoice
    common_data = {}

    # Common patterns for invoice header data
    header_patterns = {
        'invoice_no': r'(?:#\s*:?\s*|Invoice\s*#?\s*:?\s*|INVOICE\s*NO\.?\s*:?\s*)([A-Z0-9\-/]+)',
        'date': r'(?:Invoice\s*Date\s*:?\s*|DATE\s*:?\s*|Date\s*:?\s*)([\d/.\-]+)',
        # 'receiver_name': r'(?:Bill\s*To|Receiver|Billed\s*to)\s*[:.-]\s*([A-Za-z0-9\s.,]+)', # Commented out
        # 'receiver_gst': r'(?:GSTIN\s*:?\s*|GST\s*#?\s*:?\s*)([A-Z0-9]{15})', # Commented out - too generic, picks up sender GST
        'taxrate': r'(?:CGST|SGST)\s*(\d+(?:\.\d+)?)\s*%',
        'cgst': r'CGST\d*\s*\(\d+%\)\s*([\d,]+\.?\d*)',
        'sgst': r'SGST\d*\s*\(\d+%\)\s*([\d,]+\.?\d*)',
        'invoice_value': r'(?:Total\s*:?\s*|TOTAL\s*:?\s*)(?:Rs\.?|INR|₹)?\s*([\d,]+\.?\d*)',
        'total_invoice_value': r'(?:Balance\s*Due\s*:?\s*|GRAND\s*TOTAL\s*:?\s*|FINAL\s*TOTAL\s*:?\s*)(?:Rs\.?|INR|₹)?\s*([\d,]+\.?\d*)'
    }

    # Extract header data using regex patterns
    for field, pattern in header_patterns.items():
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            value = match.group(1).strip()
            # Clean up the value
            value = re.sub(r'[^\w\s.,/-]', '', value)  # Remove special characters except common ones
            common_data[field] = value

    # Specialized extraction for Receiver Name
    # Matches "Bill To" followed optionally by : or . and surrounding whitespace/newlines, then captures the next meaningful lines (up to 3)
    # This handles cases where the next line is "Ship To" (interleaved headers) or empty
    rec_name_pattern = r'(?:Bill\s*To|Receiver|Billed\s*to)\s*[:\.]?\s*((?:[^\r\n]+[\r\n]*){1,4})'
    rec_name_match = re.search(rec_name_pattern, text, re.IGNORECASE)
    if rec_name_match:
        # Get the block of text following "Bill To"
        candidate_lines = rec_name_match.group(1).splitlines()
        for line in candidate_lines:
            clean_name = line.strip()
            # Skip if it's too short, or is a known header keyword like "Ship To", "GSTIN", "Date"
            # converting to lower for checks
            check = clean_name.lower()
            if (len(clean_name) > 2 and 
                not any(x in check for x in ['gstin', 'invoice', 'date', 'ship to', 'shipment', 'place of supply', 'terms'])):
                 # Further cleanup: sometimes "Receiver: Name" is captured, we want just "Name"
                 clean_name = re.sub(r'^(?:M/s|Mr\.|Mrs\.|Dr\.)\s*', '', clean_name, flags=re.IGNORECASE)
                 common_data['receiver_name'] = clean_name
                 break # Found a valid name line, stop looking

    # Specialized extraction for Receiver GST (prioritize Bill To section)
    # Strategy: Look for "Bill To" followed by "GSTIN" within reasonable distance
    receiver_gst_match = re.search(r'(?:Bill\s*To|Receiver|Billed\s*to)[\s\S]{0,500}?(?:GSTIN|GST\s*#?)[\s.:]*([A-Z0-9]{15})', text, re.IGNORECASE | re.MULTILINE)
    if receiver_gst_match:
         common_data['receiver_gst'] = receiver_gst_match.group(1).strip()
    else:
        # Fallback: Find ALL GSTs and if there are multiple, assume the second one is receiver
        # If there's only one, it might be the only one present.
        all_gsts = re.findall(r'(?:GSTIN\s*:?\s*|GST\s*#?\s*:?\s*)([A-Z0-9]{15})', text, re.IGNORECASE)
        # 09BBDPY4789B1Z5 is the sender's GST (hardcoded check only if strictly necessary, strictly context is better)
        if all_gsts:
             if len(all_gsts) > 1:
                 # Usually first is sender, second is receiver
                 common_data['receiver_gst'] = all_gsts[1]
             else:
                 common_data['receiver_gst'] = all_gsts[0]

    # Extract table data to get all line items
    all_items = []
    if pdf_path:
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    tables = page.extract_tables()
                    for table in tables:
                        if not table:
                            continue

                        # Try to identify column indices from a header row
                        # Scan first few rows to find a likely header row
                        header_row = None
                        header_row_idx = -1
                        
                        for idx, row in enumerate(table[:10]): # Look at first 10 rows
                            row_str = str(row).lower()
                            # Check for key columns that signify a header
                            if 'description' in row_str or 'qty' in row_str or ('hsn' in row_str and 'sac' in row_str):
                                header_row = row
                                header_row_idx = idx
                                break
                        
                        if header_row is None:
                             header_row = table[0]
                             header_row_idx = 0

                        col_map = {}
                        
                        # Helper to find column index from keywords
                        def find_col_idx(headers, keywords):
                            for idx, h in enumerate(headers):
                                if h and any(k in str(h).lower() for k in keywords):
                                    return idx
                            return None

                        # Map columns dynamically based on headers
                        col_map['sno'] = find_col_idx(header_row, ['s.no', 'serial', 'sr.', 'no.'])
                        col_map['hsn'] = find_col_idx(header_row, ['hsn', 'sac', 'code'])
                        col_map['qty'] = find_col_idx(header_row, ['qty', 'quantity', 'unit'])
                        col_map['rate'] = find_col_idx(header_row, ['rate', 'taxable', 'price'])
                        col_map['discount'] = find_col_idx(header_row, ['disc', 'less'])
                        
                        # Special handling for Tax columns: prefer "Amount" or "Amt" specific columns if available
                        # But often they are just labeled "CGST", "SGST" and split into Rate/Amt
                        col_map['cgst'] = find_col_idx(header_row, ['cgst'])
                        col_map['sgst'] = find_col_idx(header_row, ['sgst'])
                        col_map['amount'] = find_col_idx(header_row, ['amount', 'total', 'value'])

                        # Check if sub-headers exist (row after header) for Tax Amount
                        if header_row_idx + 1 < len(table):
                             sub_header = table[header_row_idx + 1]
                             # If we found a CGST column, check if 'Amt' is near it in sub-header
                             if col_map['cgst'] is not None:
                                 # Look at columns starting from cgst idx
                                 for offset in range(3): # Check current and next 2 cols
                                     chk_idx = col_map['cgst'] + offset
                                     if chk_idx < len(sub_header):
                                         val = str(sub_header[chk_idx]).lower()
                                         if 'amt' in val or 'amount' in val:
                                             col_map['cgst_amt_idx'] = chk_idx
                                             break
                             
                             if col_map['sgst'] is not None:
                                 for offset in range(3):
                                     chk_idx = col_map['sgst'] + offset
                                     if chk_idx < len(sub_header):
                                         val = str(sub_header[chk_idx]).lower()
                                         if 'amt' in val or 'amount' in val:
                                             col_map['sgst_amt_idx'] = chk_idx
                                             break
                        
                        # If we didn't find clear headers (especially HSN), likely the specific original format
                        # or a format with complex headers. Fallback to original hardcoded indices for backward compatibility
                        # but check length effectively.
                        if col_map.get('hsn') is None:
                            col_map = {
                                'sno': 1, 'hsn': 3, 'qty': 4, 'rate': 5, 
                                'discount': 6, 'cgst': 10, 'sgst': 12, 'amount': 13
                            }

                        for row_idx, row in enumerate(table):
                            # Skip header rows
                            if row_idx <= header_row_idx:
                                continue
                            # Skip sub-header row if it looks like one (contains 'Amt', '%')
                            if row_idx == header_row_idx + 1 and any(x in str(row).lower() for x in ['amt', '%']):
                                continue

                            # Safe extraction helper
                            def get_val(idx):
                                if idx is not None and isinstance(idx, int) and 0 <= idx < len(row):
                                    return row[idx]
                                return ''

                            hsn_val = get_val(col_map.get('hsn'))
                            qty_val = get_val(col_map.get('qty'))
                            rate_val = get_val(col_map.get('rate'))
                            discount_val = get_val(col_map.get('discount'))
                            
                            # Use found amount indices if available, else fallback to standard
                            cgst_val = get_val(col_map.get('cgst_amt_idx', col_map.get('cgst')))
                            sgst_val = get_val(col_map.get('sgst_amt_idx', col_map.get('sgst')))
                            
                            # Heuristic fix: If extracted GST value looks like a Rate (e.g. "9", "9%") and not an Amount,
                            # and we didn't find an explicit 'Amt' column, try to look ahead for the amount.
                            if not col_map.get('cgst_amt_idx') and cgst_val and re.match(r'^\d+(\.\d+)?\s*%?$', str(cgst_val).strip()):
                                # Current value is likely a rate. Check next 2 columns for an amount.
                                base_idx = col_map.get('cgst')
                                if base_idx is not None:
                                    for offset in [1, 2]:
                                        next_val = get_val(base_idx + offset)
                                        if next_val and re.match(r'[\d,]+\.\d{2}', str(next_val).strip()):
                                            cgst_val = next_val
                                            break

                            if not col_map.get('sgst_amt_idx') and sgst_val and re.match(r'^\d+(\.\d+)?\s*%?$', str(sgst_val).strip()):
                                base_idx = col_map.get('sgst')
                                if base_idx is not None:
                                    for offset in [1, 2]:
                                        next_val = get_val(base_idx + offset)
                                        if next_val and re.match(r'[\d,]+\.\d{2}', str(next_val).strip()):
                                            sgst_val = next_val
                                            break
                            
                            invoice_val = get_val(col_map.get('amount'))
                            sno_val = get_val(col_map.get('sno'))

                            # Check if this row contains valid item data
                            hsn_clean = str(hsn_val).strip().replace('\n', '').replace(' ', '')
                            
                            # Valid item row: has serial number (digits) and HSN (digits)
                            # Relaxed check: if we have HSN and (SNO or some value), consider it valid
                            if (hsn_clean and re.search(r'\d{2,8}', hsn_clean)):
                                item_data = {
                                    'sno': str(sno_val).strip() if sno_val else str(len(all_items) + 1),
                                    'hsn': str(hsn_val).strip(),
                                    'quantity': '',
                                    'taxable_amount': '',
                                    'discount': '',
                                    'taxrate': '18%',  # Default GST rate
                                    'cgst': '',
                                    'sgst': '',
                                    'invoice_value': ''
                                }

                                # Extract quantity
                                if qty_val:
                                    qty_match = re.search(r'([\d,]+\.?\d*)', str(qty_val).strip())
                                    if qty_match:
                                        item_data['quantity'] = qty_match.group(1)

                                # Extract taxable amount (rate)
                                if rate_val:
                                    rate_match = re.search(r'([\d,]+\.?\d*)', str(rate_val).strip())
                                    if rate_match:
                                        item_data['taxable_amount'] = rate_match.group(1)

                                # Extract discount
                                if discount_val:
                                    item_data['discount'] = str(discount_val).strip()

                                # Extract CGST
                                if cgst_val:
                                    cgst_match = re.search(r'([\d,]+\.?\d*)', str(cgst_val).strip())
                                    if cgst_match:
                                        item_data['cgst'] = cgst_match.group(1)

                                # Extract SGST
                                if sgst_val:
                                    sgst_match = re.search(r'([\d,]+\.?\d*)', str(sgst_val).strip())
                                    if sgst_match:
                                        item_data['sgst'] = sgst_match.group(1)

                                # Extract invoice value (amount for this line)
                                if invoice_val:
                                    invoice_match = re.search(r'([\d,]+\.?\d*)', str(invoice_val).strip())
                                    if invoice_match:
                                        item_data['invoice_value'] = invoice_match.group(1)

                                all_items.append(item_data)
        except Exception as e:
            print(f"Error extracting table data: {e}")

    # Aggregation Logic
    if all_items:
        aggregated_items = {}
        for item in all_items:
            hsn = item['hsn']
            if not hsn: # Skip if no HSN
                continue

            if hsn not in aggregated_items:
                aggregated_items[hsn] = {
                    'sno': item['sno'], # Keep first SNO
                    'hsn': hsn,
                    'quantity': 0.0,
                    'taxable_amount': 0.0,
                    'taxrate': item['taxrate'], # Assume same for same HSN
                    'cgst': 0.0,
                    'sgst': 0.0,
                    'invoice_value': 0.0,
                    'count': 0
                }
            
            # Helper to safely parse float
            def parse_float(val):
                try:
                    return float(str(val).replace(',', ''))
                except (ValueError, TypeError):
                    return 0.0

            # Aggregate values
            agg = aggregated_items[hsn]
            agg['quantity'] += parse_float(item['quantity'])
            agg['taxable_amount'] += parse_float(item['taxable_amount'])
            agg['cgst'] += parse_float(item['cgst'])
            agg['sgst'] += parse_float(item['sgst'])
            agg['invoice_value'] += parse_float(item['invoice_value'])
            agg['count'] += 1

        # Replace all_items with aggregated list
        if aggregated_items:
             new_all_items = []
             for idx, (hsn, agg) in enumerate(aggregated_items.items(), 1):
                 new_all_items.append({
                     'sno': str(idx),
                     'hsn': hsn,
                     'quantity': f"{agg['quantity']:.2f}",
                     'taxable_amount': f"{agg['taxable_amount']:.2f}",
                     # 'discount': '', # Discount removed
                     'taxrate': agg['taxrate'],
                     'cgst': f"{agg['cgst']:.2f}",
                     'sgst': f"{agg['sgst']:.2f}",
                     'invoice_value': f"{agg['invoice_value']:.2f}"
                 })
             all_items = new_all_items

    # If no table items found, create a single item with empty values
    if not all_items:
        all_items = [{
            'sno': '1',
            'hsn': '',
            'quantity': '',
            'taxable_amount': '',
            'discount': '', # Kept for structure but unused
            'taxrate': '',
            'cgst': '',
            'sgst': '',
            'invoice_value': ''
        }]

    # Create final data list - one entry per item with merged cells logic
    final_data = []
    for i, item in enumerate(all_items):
        if i == 0:
            # First item: include all invoice-level fields
            row_data = {
                'sno': item['sno'],  # Use actual SNO from table
                'invoice_no': common_data.get('invoice_no', ''),
                'date': common_data.get('date', ''),
                'receiver_name': common_data.get('receiver_name', ''),
                'receiver_gst': common_data.get('receiver_gst', ''),
                'hsn': item['hsn'],
                'quantity': item['quantity'],
                'taxable_amount': item['taxable_amount'],
                # 'discount': item.get('discount', ''), # Removed
                'taxrate': item['taxrate'],
                'cgst': item['cgst'],
                'sgst': item['sgst'],
                'invoice_value': item['invoice_value'],
                'total_invoice_value': ''  # Empty for all item rows
            }
        else:
            # Subsequent items: empty invoice fields, filled item fields
            row_data = {
                'sno': item['sno'],  # Use actual SNO from table
                'invoice_no': '',  # Empty
                'date': '',  # Empty
                'receiver_name': '',  # Empty
                'receiver_gst': '',  # Empty
                'hsn': item['hsn'],
                'quantity': item['quantity'],
                'taxable_amount': item['taxable_amount'],
                # 'discount': item.get('discount', ''), # Removed
                'taxrate': item['taxrate'],
                'cgst': item['cgst'],
                'sgst': item['sgst'],
                'invoice_value': item['invoice_value'],
                'total_invoice_value': ''  # Empty for all item rows
            }
        final_data.append(row_data)

    # Add final row with total invoice value
    final_data.append({
        'sno': '',  # Empty
        'invoice_no': '',  # Empty
        'date': '',  # Empty
        'receiver_name': '',  # Empty
        'receiver_gst': '',  # Empty
        'hsn': '',  # Empty
        'quantity': '',  # Empty
        'taxable_amount': '',  # Empty
        # 'discount': '',  # Removed
        'taxrate': '',  # Empty
        'cgst': '',  # Empty
        'sgst': '',  # Empty
        'invoice_value': '',  # Empty
        'total_invoice_value': common_data.get('total_invoice_value', '')  # Total in last row
    })


    return final_data

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_files():
    if 'files' not in request.files:
        flash('No file part')
        return redirect(url_for('index'))

    files = request.files.getlist('files')
    if not files or files[0].filename == '':
        flash('No selected files')
        return redirect(url_for('index'))

    processed_files = []
    all_data = []

    for file in files:
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            unique_id = str(uuid.uuid4())
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{unique_id}_{filename}")
            file.save(file_path)

            # Process the PDF
            extracted_data = process_pdf(file_path, filename, unique_id)
            processed_files.append(extracted_data)
            all_data.extend(extracted_data.get('parsed_data', []))

    # Always create consolidated Excel file
    excel_filename = f"consolidated_{uuid.uuid4()}.xlsx"
    excel_path = os.path.join(app.config['PROCESSED_FOLDER'], excel_filename)
    create_consolidated_excel(all_data, excel_path)

    return render_template('results.html',
                         processed_files=processed_files,
                         excel_download=excel_filename,
                         consolidated=True,
                         all_data=all_data)

def process_pdf(file_path, original_filename, unique_id):
    """Process a single PDF file"""
    # Extract text
    text = extract_text_from_pdf(file_path)

    # If little text found, try OCR
    if len(text.strip()) < 100:
        print("Little text found, attempting OCR...")
        text = extract_text_with_ocr(file_path)

    # Extract tables
    tables = extract_tables_from_pdf(file_path)

    # Parse structured data
    parsed_data_list = parse_invoice_data(text, file_path)

    # Create individual Excel file
    excel_filename = f"{unique_id}_extracted.xlsx"
    excel_path = os.path.join(app.config['PROCESSED_FOLDER'], excel_filename)

    create_excel_file(parsed_data_list, tables, text, excel_path)

    return {
        'filename': original_filename,
        'unique_id': unique_id,
        'text': text[:1000] + "..." if len(text) > 1000 else text,
        'tables_count': len(tables),
        'parsed_data': parsed_data_list,
        'excel_path': excel_filename
    }

def create_excel_file(parsed_data, tables, raw_text, output_path):
    """Create Excel file with extracted data"""
    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
        sheets_created = 0

        # Parsed data sheet
        if parsed_data and len(parsed_data) > 0:
            try:
                # parsed_data is now a list of dictionaries (one per item)
                df_parsed = pd.DataFrame(parsed_data)
                df_parsed.to_excel(writer, sheet_name='Parsed_Data', index=False)
                sheets_created += 1
            except Exception as e:
                print(f"Error creating parsed data sheet: {e}")
                # If DataFrame creation fails, try with original data
                try:
                    if parsed_data:
                        df_parsed = pd.DataFrame(parsed_data)
                        df_parsed.to_excel(writer, sheet_name='Parsed_Data', index=False)
                        sheets_created += 1
                except Exception as e2:
                    print(f"Error creating parsed data sheet with original data: {e2}")

        # Tables sheet
        if tables:
            for i, table_info in enumerate(tables):
                try:
                    sheet_name = f'Table_{table_info["page"]}_{i+1}'
                    table_info['data'].to_excel(writer, sheet_name=sheet_name, index=False)
                    sheets_created += 1
                except Exception as e:
                    print(f"Error creating table sheet: {e}")

        # Raw text sheet
        if raw_text and raw_text.strip():
            try:
                df_text = pd.DataFrame({'Raw_Text': [raw_text]})
                df_text.to_excel(writer, sheet_name='Raw_Text', index=False)
                sheets_created += 1
            except Exception as e:
                print(f"Error creating raw text sheet: {e}")

        # If no sheets were created, create a default sheet
        if sheets_created == 0:
            try:
                df_empty = pd.DataFrame({'Message': ['No data could be extracted from this PDF']})
                df_empty.to_excel(writer, sheet_name='No_Data', index=False)
            except Exception as e:
                print(f"Error creating default sheet: {e}")

def create_consolidated_excel(all_data, output_path):
    """Create consolidated Excel for multiple files with all invoice data"""
    # Define the column order as requested
    columns = ['sno', 'invoice_no', 'date', 'receiver_name', 'receiver_gst', 'hsn',
               'quantity', 'taxable_amount', 'taxrate', 'cgst', 'sgst',
               'invoice_value', 'total_invoice_value']

    # Create DataFrame with specified columns
    if all_data:
        df = pd.DataFrame(all_data)

        # Ensure all required columns exist
        for col in columns:
            if col not in df.columns:
                df[col] = ''

        # Reorder columns as specified
        df = df[columns]
    else:
        # Create empty DataFrame with proper columns
        df = pd.DataFrame(columns=columns)

    # Rename columns to match user's requirements
    column_mapping = {
        'sno': 'SNO',
        'invoice_no': 'INVOICE NO',
        'date': 'DATE',
        'receiver_name': 'RECEIVER NAME',
        'receiver_gst': 'RECEIVER GST',
        'hsn': 'HSN',
        'quantity': 'QUANTITY',
        'taxable_amount': 'TAXABLE AMOUNT',
        # 'discount': 'DISCOUNT', # Removed
        'taxrate': 'TAXRATE',
        'cgst': 'CGST',
        'sgst': 'SGST',
        'invoice_value': 'INVOICE VALUE',
        'total_invoice_value': 'TOTAL INVOICE VALUE'
    }

    df = df.rename(columns=column_mapping)

    # Save to Excel
    df.to_excel(output_path, index=False)

    return output_path

@app.route('/download/<filename>')
def download_file(filename):
    file_path = os.path.join(app.config['PROCESSED_FOLDER'], filename)
    if os.path.exists(file_path):
        return send_file(file_path, as_attachment=True)
    else:
        flash('File not found')
        return redirect(url_for('index'))

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)